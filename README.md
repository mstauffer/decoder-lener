# Generative SLMs Meet Brazilian Legal Documents: Efficient NER via LoRA Fine-tuning

<p align="center">
    <img src="imgs/ner_teaching.png" alt="NER Teaching Example" width="50%">
</p>

This repo holds the code for the BRACIS 2025 paper Generative SLMs Meet Brazilian Legal Documents: Efficient NER via LoRA Fine-tuning. In a nutshell, the project aimed to do Named Entity Recognition (NER) using Small Language Models (SLMs) and Parameter-Efficient Fine-Tuning (PEFT) techniques. Specifically, we focused on using the Qwen3 SLM family along with the LoRA PEFT technique, with experiments made on the [LeNER-BR](https://github.com/peluz/lener-br) dataset.

## Authors

- [Matheus Stauffer Viana de Oliveira](http://lattes.cnpq.br/3634456971616689)
- [Pedro Borges Pio](http://lattes.cnpq.br/0113233013099102)
- [Lu√≠s Paulo Faina Garcia](https://lpfgarcia.github.io/index/index.html)

## Features
- Parameter-efficient fine-tuning for NER tasks
- Named Entity Recognition implementation
- Resource-efficient model training

## Getting Started

For retraining the model used on the paper, use the Jupyter Notebook namely after `training_qwen3-full-8b.ipynb`. The library management is the default for Python:

```
python3 -m venv venv
pip install -r requirements.txt
```

For running the evaluation step, please proceed with

```
python3 src/scripts/eval_seqeval3.py <qwen_checkpoint_path> Qwen/Qwen3-8B 0 full
```

The results generated by us are inside the `reports` folder.