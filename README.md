# Generative SLMs Meet Brazilian Legal Documents: Efficient NER via LoRA Fine-tuning

<p align="center">
    <a href="https://huggingface.co/datasets">
        <img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/dataset-on-hf-sm-dark.svg" alt="Dataset on HF"/>
    </a>
    <a href="https://huggingface.co/models">
        <img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/model-on-hf-sm-dark.svg" alt="Model on HF"/>
    </a>
</p>



<p align="center">
    <img src="imgs/ner_teaching.png" alt="NER Teaching Example" width="50%">
</p>

This repo holds the code for the BRACIS 2025 paper Generative SLMs Meet Brazilian Legal Documents: Efficient NER via LoRA Fine-tuning. In a nutshell, the project aimed to do Named Entity Recognition (NER) using Small Language Models (SLMs) and Parameter-Efficient Fine-Tuning (PEFT) techniques. Specifically, we focused on using the Qwen3 SLM family along with the LoRA PEFT technique, with experiments made on the [LeNER-BR](https://github.com/peluz/lener-br) dataset.

## Authors

- [Matheus Stauffer Viana de Oliveira](http://lattes.cnpq.br/3634456971616689)
- [Pedro Borges Pio](http://lattes.cnpq.br/0113233013099102)
- [Lu√≠s Paulo Faina Garcia](https://lpfgarcia.github.io/index/index.html)

## Features
- Parameter-efficient fine-tuning for NER tasks
- Named Entity Recognition implementation
- Resource-efficient model training

## Getting Started

To install the required dependencies, use your preferred package manager. For example, with `pip`:

```
python3 -m venv venv
pip install -r requirements.txt
```

To retrain the model as described in the paper, use the Jupyter Notebook namely after `training_qwen3-full-8b.ipynb`. To run the evaluation step, execute:

```
python3 src/scripts/eval_seqeval3.py <qwen_checkpoint_path> Qwen/Qwen3-8B 0 full
```

where `<qwen_checkpoint_path>` is the path for the created model checkpoints.

The results generated by us are inside the `reports` folder.